version: '3.8'

services:
  multi_tool_mcp:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${PORT:-8070}:8070"
    volumes:
      # Mount local directories for persistent data if needed
      - ./assets:/app/assets
      - ./hf_cache:/app/hf_cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    restart: unless-stopped
    environment:
      # FastAPI/Uvicorn environment variables
      - UVICORN_HOST=0.0.0.0
      - UVICORN_PORT=8070
      - PYTHONPATH=/app
      # Optional: Enable debug mode (remove in production)
      - UVICORN_RELOAD=false
      # Make NVIDIA GPUs visible and specify capabilities for PyTorch
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    
    # Health check to monitor service status
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8070/docs"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

# Define named volumes for persistent data
volumes:
  logs:
  data:
  assets:
